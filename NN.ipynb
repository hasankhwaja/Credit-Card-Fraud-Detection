{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f32750f0-9378-4025-a802-e67e1109931e",
      "metadata": {
        "id": "f32750f0-9378-4025-a802-e67e1109931e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from math import radians, cos, sin, asin, sqrt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "def preprocess_fraud_data(file_path):\n",
        "    \"\"\"\n",
        "    Preprocess the fraud dataset and split into training and validation sets.\n",
        "\n",
        "    Parameters:\n",
        "        file_path (str): Path to the input CSV file.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Processed training and validation sets (X_train, X_val, y_train, y_val).\n",
        "    \"\"\"\n",
        "    # Load the dataset\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Convert 'trans_date_trans_time' to datetime\n",
        "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
        "\n",
        "    # Calculate age using 'dob' and transaction year\n",
        "    df['transaction_year'] = df['trans_date_trans_time'].dt.year\n",
        "    df['year_of_birth'] = pd.to_datetime(df['dob']).dt.year\n",
        "    df['age'] = df['transaction_year'] - df['year_of_birth']\n",
        "    df.drop(columns=['dob', 'transaction_year', 'year_of_birth'], inplace=True)\n",
        "\n",
        "    # Drop irrelevant columns\n",
        "    irrelevant_columns = ['Unnamed: 0', 'cc_num', 'trans_num', 'street']\n",
        "    df_cleaned = df.drop(columns=irrelevant_columns)\n",
        "\n",
        "    # Haversine function to calculate distance\n",
        "    def haversine(lat1, lon1, lat2, lon2):\n",
        "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "        dlon = lon2 - lon1\n",
        "        dlat = lat2 - lat1\n",
        "        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
        "        c = 2 * asin(sqrt(a))\n",
        "        r = 6371  # Radius of Earth in kilometers.\n",
        "        return c * r\n",
        "\n",
        "    # Calculate distance and add to the dataset\n",
        "    df_cleaned['distance'] = df_cleaned.apply(\n",
        "        lambda row: haversine(row['lat'], row['long'], row['merch_lat'], row['merch_long']), axis=1)\n",
        "\n",
        "    # Create bins for latitude and longitude\n",
        "    n_bins = 10\n",
        "    df_cleaned['lat_bucket'] = pd.cut(df_cleaned['lat'], bins=n_bins, labels=False)\n",
        "    df_cleaned['long_bucket'] = pd.cut(df_cleaned['long'], bins=n_bins, labels=False)\n",
        "    df_cleaned['merch_lat_bucket'] = pd.cut(df_cleaned['merch_lat'], bins=n_bins, labels=False)\n",
        "    df_cleaned['merch_long_bucket'] = pd.cut(df_cleaned['merch_long'], bins=n_bins, labels=False)\n",
        "\n",
        "    # Encode categorical columns\n",
        "    categorical_columns = ['merchant', 'category', 'gender', 'job']\n",
        "    label_encoders = {}\n",
        "    for col in categorical_columns:\n",
        "        le = LabelEncoder()\n",
        "        df_cleaned[col] = le.fit_transform(df_cleaned[col])\n",
        "        label_encoders[col] = le\n",
        "\n",
        "    # Drop columns that are no longer needed\n",
        "    columns_to_drop = ['trans_date_trans_time', 'first', 'last', 'city', 'state', 'zip', 'lat', 'long', 'merch_lat',\n",
        "                       'merch_long']\n",
        "    df_cleaned = df_cleaned.drop(columns=columns_to_drop)\n",
        "\n",
        "    # Separate features and target variable\n",
        "    X = df_cleaned.drop(columns=['is_fraud'])\n",
        "    y = df_cleaned['is_fraud']\n",
        "\n",
        "    # Normalize numerical columns\n",
        "    numerical_columns = ['amt', 'age', 'distance', 'lat_bucket', 'long_bucket', 'merch_lat_bucket', 'merch_long_bucket']\n",
        "    scaler = StandardScaler()\n",
        "    X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
        "\n",
        "    # Split into training and validation sets (fixed parameters)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    return X_train, X_val, y_train, y_val, scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ff8f26-471b-498c-a58b-6f0780079b17",
      "metadata": {
        "id": "78ff8f26-471b-498c-a58b-6f0780079b17"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val, scaler = preprocess_fraud_data('fraudTrain.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4695b9c-4b3f-4d2c-a82b-6efd4dc318e1",
      "metadata": {
        "id": "b4695b9c-4b3f-4d2c-a82b-6efd4dc318e1",
        "outputId": "5ddbd42b-7201-4c9e-8235-400804e2b0aa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>merchant</th>\n",
              "      <th>category</th>\n",
              "      <th>amt</th>\n",
              "      <th>gender</th>\n",
              "      <th>city_pop</th>\n",
              "      <th>job</th>\n",
              "      <th>unix_time</th>\n",
              "      <th>age</th>\n",
              "      <th>distance</th>\n",
              "      <th>lat_bucket</th>\n",
              "      <th>long_bucket</th>\n",
              "      <th>merch_lat_bucket</th>\n",
              "      <th>merch_long_bucket</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>330201</th>\n",
              "      <td>340</td>\n",
              "      <td>13</td>\n",
              "      <td>-0.398220</td>\n",
              "      <td>0</td>\n",
              "      <td>1178</td>\n",
              "      <td>99</td>\n",
              "      <td>1338993811</td>\n",
              "      <td>1.263965</td>\n",
              "      <td>-0.481499</td>\n",
              "      <td>-1.315578</td>\n",
              "      <td>-0.157062</td>\n",
              "      <td>-1.405042</td>\n",
              "      <td>-0.119944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>798518</th>\n",
              "      <td>476</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.313013</td>\n",
              "      <td>0</td>\n",
              "      <td>85</td>\n",
              "      <td>390</td>\n",
              "      <td>1354562808</td>\n",
              "      <td>-0.634511</td>\n",
              "      <td>1.211505</td>\n",
              "      <td>2.240190</td>\n",
              "      <td>-2.252357</td>\n",
              "      <td>1.337741</td>\n",
              "      <td>-2.235703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260375</th>\n",
              "      <td>571</td>\n",
              "      <td>5</td>\n",
              "      <td>-0.215206</td>\n",
              "      <td>0</td>\n",
              "      <td>24536</td>\n",
              "      <td>300</td>\n",
              "      <td>1370692963</td>\n",
              "      <td>-0.519452</td>\n",
              "      <td>-0.392995</td>\n",
              "      <td>-1.315578</td>\n",
              "      <td>-0.157062</td>\n",
              "      <td>-1.405042</td>\n",
              "      <td>-0.119944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412511</th>\n",
              "      <td>357</td>\n",
              "      <td>3</td>\n",
              "      <td>-0.175535</td>\n",
              "      <td>1</td>\n",
              "      <td>3096</td>\n",
              "      <td>423</td>\n",
              "      <td>1341539214</td>\n",
              "      <td>-0.116745</td>\n",
              "      <td>0.001850</td>\n",
              "      <td>1.351248</td>\n",
              "      <td>0.541370</td>\n",
              "      <td>1.337741</td>\n",
              "      <td>0.585309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344644</th>\n",
              "      <td>197</td>\n",
              "      <td>7</td>\n",
              "      <td>-0.081782</td>\n",
              "      <td>0</td>\n",
              "      <td>128354</td>\n",
              "      <td>452</td>\n",
              "      <td>1339371240</td>\n",
              "      <td>-1.094747</td>\n",
              "      <td>1.553005</td>\n",
              "      <td>0.462306</td>\n",
              "      <td>-0.157062</td>\n",
              "      <td>0.423480</td>\n",
              "      <td>-0.119944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110268</th>\n",
              "      <td>590</td>\n",
              "      <td>2</td>\n",
              "      <td>0.012656</td>\n",
              "      <td>0</td>\n",
              "      <td>1478</td>\n",
              "      <td>310</td>\n",
              "      <td>1330829368</td>\n",
              "      <td>0.458551</td>\n",
              "      <td>1.056812</td>\n",
              "      <td>1.351248</td>\n",
              "      <td>-0.157062</td>\n",
              "      <td>1.337741</td>\n",
              "      <td>-0.119944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259178</th>\n",
              "      <td>191</td>\n",
              "      <td>9</td>\n",
              "      <td>-0.424294</td>\n",
              "      <td>0</td>\n",
              "      <td>5438</td>\n",
              "      <td>270</td>\n",
              "      <td>1336546444</td>\n",
              "      <td>0.516081</td>\n",
              "      <td>1.275304</td>\n",
              "      <td>0.462306</td>\n",
              "      <td>1.239802</td>\n",
              "      <td>0.423480</td>\n",
              "      <td>1.290563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131932</th>\n",
              "      <td>680</td>\n",
              "      <td>6</td>\n",
              "      <td>0.298903</td>\n",
              "      <td>0</td>\n",
              "      <td>310</td>\n",
              "      <td>439</td>\n",
              "      <td>1331675187</td>\n",
              "      <td>-0.289333</td>\n",
              "      <td>-1.389976</td>\n",
              "      <td>-0.426636</td>\n",
              "      <td>-0.855493</td>\n",
              "      <td>-0.490781</td>\n",
              "      <td>-0.825197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671155</th>\n",
              "      <td>409</td>\n",
              "      <td>12</td>\n",
              "      <td>-0.403896</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>149</td>\n",
              "      <td>1350120506</td>\n",
              "      <td>1.781731</td>\n",
              "      <td>1.388977</td>\n",
              "      <td>2.240190</td>\n",
              "      <td>-0.157062</td>\n",
              "      <td>1.337741</td>\n",
              "      <td>-0.825197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121958</th>\n",
              "      <td>11</td>\n",
              "      <td>10</td>\n",
              "      <td>0.439002</td>\n",
              "      <td>0</td>\n",
              "      <td>530</td>\n",
              "      <td>26</td>\n",
              "      <td>1331316795</td>\n",
              "      <td>-0.922159</td>\n",
              "      <td>0.051200</td>\n",
              "      <td>-0.426636</td>\n",
              "      <td>0.541370</td>\n",
              "      <td>-0.490781</td>\n",
              "      <td>0.585309</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1037340 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         merchant  category       amt  gender  city_pop  job   unix_time  \\\n",
              "330201        340        13 -0.398220       0      1178   99  1338993811   \n",
              "798518        476         0 -0.313013       0        85  390  1354562808   \n",
              "1260375       571         5 -0.215206       0     24536  300  1370692963   \n",
              "412511        357         3 -0.175535       1      3096  423  1341539214   \n",
              "344644        197         7 -0.081782       0    128354  452  1339371240   \n",
              "...           ...       ...       ...     ...       ...  ...         ...   \n",
              "110268        590         2  0.012656       0      1478  310  1330829368   \n",
              "259178        191         9 -0.424294       0      5438  270  1336546444   \n",
              "131932        680         6  0.298903       0       310  439  1331675187   \n",
              "671155        409        12 -0.403896       1       140  149  1350120506   \n",
              "121958         11        10  0.439002       0       530   26  1331316795   \n",
              "\n",
              "              age  distance  lat_bucket  long_bucket  merch_lat_bucket  \\\n",
              "330201   1.263965 -0.481499   -1.315578    -0.157062         -1.405042   \n",
              "798518  -0.634511  1.211505    2.240190    -2.252357          1.337741   \n",
              "1260375 -0.519452 -0.392995   -1.315578    -0.157062         -1.405042   \n",
              "412511  -0.116745  0.001850    1.351248     0.541370          1.337741   \n",
              "344644  -1.094747  1.553005    0.462306    -0.157062          0.423480   \n",
              "...           ...       ...         ...          ...               ...   \n",
              "110268   0.458551  1.056812    1.351248    -0.157062          1.337741   \n",
              "259178   0.516081  1.275304    0.462306     1.239802          0.423480   \n",
              "131932  -0.289333 -1.389976   -0.426636    -0.855493         -0.490781   \n",
              "671155   1.781731  1.388977    2.240190    -0.157062          1.337741   \n",
              "121958  -0.922159  0.051200   -0.426636     0.541370         -0.490781   \n",
              "\n",
              "         merch_long_bucket  \n",
              "330201           -0.119944  \n",
              "798518           -2.235703  \n",
              "1260375          -0.119944  \n",
              "412511            0.585309  \n",
              "344644           -0.119944  \n",
              "...                    ...  \n",
              "110268           -0.119944  \n",
              "259178            1.290563  \n",
              "131932           -0.825197  \n",
              "671155           -0.825197  \n",
              "121958            0.585309  \n",
              "\n",
              "[1037340 rows x 13 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6693012b-8a8d-496b-ad3d-c031ef193e2f",
      "metadata": {
        "id": "6693012b-8a8d-496b-ad3d-c031ef193e2f",
        "outputId": "588273ec-7183-4b70-8236-b4918157ced7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "330201     0\n",
              "798518     0\n",
              "1260375    0\n",
              "412511     0\n",
              "344644     0\n",
              "          ..\n",
              "110268     0\n",
              "259178     0\n",
              "131932     0\n",
              "671155     0\n",
              "121958     0\n",
              "Name: is_fraud, Length: 1037340, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e9323f9-68e2-4d2f-9769-77de45573b30",
      "metadata": {
        "id": "3e9323f9-68e2-4d2f-9769-77de45573b30",
        "outputId": "67f2b545-42df-4c29-fc59-f1b3a4c3b57a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5986"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b59c39-461f-4f23-9cc5-54cab8562c55",
      "metadata": {
        "id": "44b59c39-461f-4f23-9cc5-54cab8562c55"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec34383d-e2b0-4f24-a6d2-07f81a9cf243",
      "metadata": {
        "id": "ec34383d-e2b0-4f24-a6d2-07f81a9cf243",
        "outputId": "cae8b376-f50d-44ca-d5be-59b6529a0465"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.58%\n"
          ]
        }
      ],
      "source": [
        "print(f'{(y_train.sum() / y_train.count()) * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8165594-6c4d-45bc-981e-e9783b0ffbb4",
      "metadata": {
        "id": "e8165594-6c4d-45bc-981e-e9783b0ffbb4",
        "outputId": "182fb6ce-349d-4dcb-cf87-ab743afda10c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Pat\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9884 - loss: 768235.5625 - val_accuracy: 0.9941 - val_loss: 0.1179\n",
            "Epoch 2/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 823.1498 - val_accuracy: 0.9941 - val_loss: 0.0539\n",
            "Epoch 3/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 134.2233 - val_accuracy: 0.9941 - val_loss: 0.0395\n",
            "Epoch 4/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 53.7900 - val_accuracy: 0.9941 - val_loss: 0.0363\n",
            "Epoch 5/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 12.4795 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
            "Epoch 6/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 1.5541 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
            "Epoch 7/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 9.4890 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
            "Epoch 8/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 9.2130 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
            "Epoch 9/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 5.1845 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
            "Epoch 10/10\n",
            "\u001b[1m2027/2027\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0358 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
            "\u001b[1m8105/8105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 776us/step\n",
            "Accuracy:  0.9941\n",
            "Precision: 0.0000\n",
            "Recall:    0.0000\n",
            "F1 Score:  0.0000\n",
            "\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      1.00    257815\n",
            "           1       0.00      0.00      0.00      1520\n",
            "\n",
            "    accuracy                           0.99    259335\n",
            "   macro avg       0.50      0.50      0.50    259335\n",
            "weighted avg       0.99      0.99      0.99    259335\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report\n",
        ")\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Build a simple feed-forward neural network\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=512\n",
        ")\n",
        "\n",
        "# Predict and evaluate on the validation set\n",
        "y_val_pred_proba = model.predict(X_val)\n",
        "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
        "\n",
        "accuracy  = accuracy_score(y_val, y_val_pred)\n",
        "precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
        "recall    = recall_score(y_val, y_val_pred, zero_division=0)\n",
        "f1        = f1_score(y_val, y_val_pred, zero_division=0)\n",
        "\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "\n",
        "# Report\n",
        "print(\"\\nDetailed classification report:\")\n",
        "print(classification_report(y_val, y_val_pred, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8f28fc8-bfbf-4cdb-aa53-854e588ab621",
      "metadata": {
        "id": "c8f28fc8-bfbf-4cdb-aa53-854e588ab621"
      },
      "source": [
        "A 0.00 recall in class 1 means all actual frauds were missed.\n",
        "\n",
        "Oversampling / Undersampling;\n",
        "Adjust the Threshold;\n",
        "Gather More Fraud Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08149fc5-42f6-4167-9747-b7695b1fdba7",
      "metadata": {
        "id": "08149fc5-42f6-4167-9747-b7695b1fdba7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}