{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681a4583-12c2-4a68-9967-152db721d284",
   "metadata": {},
   "source": [
    "# Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "31df9474-68a8-4bfe-b56d-15e213b80c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf1f9cc-dc5d-4077-be72-e56aa0439964",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f32750f0-9378-4025-a802-e67e1109931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fraud_data(file_path, train=True, scaler=None, label_encoders=None, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Preprocess the fraud dataset for training or testing.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the input CSV file.\n",
    "        train (bool): If True, fit scaler and encoders; if False, use provided ones.\n",
    "        scaler (StandardScaler): Fitted scaler from training data.\n",
    "        label_encoders (dict): Dictionary of fitted LabelEncoders from training.\n",
    "        test_size (float): Fraction of data for validation (if training).\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        If train=True:\n",
    "            tuple: (X_train, X_val, y_train, y_val, fitted_scaler, fitted_label_encoders)\n",
    "        If train=False:\n",
    "            tuple: (X_test, y_test)\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Convert 'trans_date_trans_time' to datetime\n",
    "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "\n",
    "    # Calculate age\n",
    "    df['transaction_year'] = df['trans_date_trans_time'].dt.year\n",
    "    df['year_of_birth'] = pd.to_datetime(df['dob']).dt.year\n",
    "    df['age'] = df['transaction_year'] - df['year_of_birth']\n",
    "    df.drop(columns=['dob', 'transaction_year', 'year_of_birth'], inplace=True)\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    irrelevant_columns = ['Unnamed: 0', 'cc_num', 'trans_num', 'street']\n",
    "    df_cleaned = df.drop(columns=irrelevant_columns)\n",
    "\n",
    "    # Haversine function to calculate distance\n",
    "    def haversine(lat1, lon1, lat2, lon2):\n",
    "        lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "        c = 2 * asin(sqrt(a))\n",
    "        r = 6371  # Earth radius in km\n",
    "        return c * r\n",
    "\n",
    "    # Compute distance feature\n",
    "    df_cleaned['distance'] = df_cleaned.apply(\n",
    "        lambda row: haversine(row['lat'], row['long'], row['merch_lat'], row['merch_long']), axis=1)\n",
    "\n",
    "    # Create latitude and longitude bins\n",
    "    n_bins = 10\n",
    "    df_cleaned['lat_bucket'] = pd.cut(df_cleaned['lat'], bins=n_bins, labels=False)\n",
    "    df_cleaned['long_bucket'] = pd.cut(df_cleaned['long'], bins=n_bins, labels=False)\n",
    "    df_cleaned['merch_lat_bucket'] = pd.cut(df_cleaned['merch_lat'], bins=n_bins, labels=False)\n",
    "    df_cleaned['merch_long_bucket'] = pd.cut(df_cleaned['merch_long'], bins=n_bins, labels=False)\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_columns = ['merchant', 'category', 'gender', 'job']\n",
    "    \n",
    "    if train:\n",
    "        label_encoders = {}\n",
    "        for col in categorical_columns:\n",
    "            le = LabelEncoder()\n",
    "            df_cleaned[col] = le.fit_transform(df_cleaned[col])\n",
    "            label_encoders[col] = le  # Save encoder for future use\n",
    "    else:\n",
    "        # Apply pre-fitted encoders\n",
    "        for col in categorical_columns:\n",
    "            df_cleaned[col] = label_encoders[col].transform(df_cleaned[col])\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['trans_date_trans_time', 'first', 'last', 'city', 'state', 'zip', 'lat', 'long', 'merch_lat', 'merch_long']\n",
    "    df_cleaned = df_cleaned.drop(columns=columns_to_drop)\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df_cleaned.drop(columns=['is_fraud'])\n",
    "    y = df_cleaned['is_fraud']\n",
    "\n",
    "    # Normalize numerical columns\n",
    "    numerical_columns = ['amt', 'age', 'distance', 'lat_bucket', 'long_bucket', 'merch_lat_bucket', 'merch_long_bucket']\n",
    "    \n",
    "    if train:\n",
    "        scaler = StandardScaler()\n",
    "        X[numerical_columns] = scaler.fit_transform(X[numerical_columns])\n",
    "\n",
    "        # Split into training and validation sets\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        return X_train, X_val, y_train, y_val, scaler, label_encoders  # Return fitted encoders & scaler\n",
    "    else:\n",
    "        X[numerical_columns] = scaler.transform(X[numerical_columns])\n",
    "        return X, y  # Return processed test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc056bf7-3a40-4310-b1e7-2639d32ee48b",
   "metadata": {},
   "source": [
    "# simple feed-forward neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78ff8f26-471b-498c-a58b-6f0780079b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess training data\n",
    "X_train, X_val, y_train, y_val, scaler, label_encoders = preprocess_fraud_data(\"fraudTrain.csv\", train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8165594-6c4d-45bc-981e-e9783b0ffbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pat\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 414693.1250 - val_accuracy: 0.9941 - val_loss: 0.1236\n",
      "Epoch 2/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 557.9031 - val_accuracy: 0.9941 - val_loss: 0.0551\n",
      "Epoch 3/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 199.4371 - val_accuracy: 0.9941 - val_loss: 0.0398\n",
      "Epoch 4/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 47.4863 - val_accuracy: 0.9941 - val_loss: 0.0364\n",
      "Epoch 5/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 12.0252 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
      "Epoch 6/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 18.0478 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
      "Epoch 7/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 16.8442 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
      "Epoch 8/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 20.8981 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
      "Epoch 9/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 3.4171 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
      "Epoch 10/10\n",
      "\u001b[1m2027/2027\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9943 - loss: 13.8235 - val_accuracy: 0.9941 - val_loss: 0.0360\n",
      "\u001b[1m8105/8105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 856us/step\n",
      "Accuracy:  0.9941\n",
      "Precision: 0.0000\n",
      "Recall:    0.0000\n",
      "F1 Score:  0.0000\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00    257815\n",
      "           1       0.00      0.00      0.00      1520\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.50      0.50      0.50    259335\n",
      "weighted avg       0.99      0.99      0.99    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a simple feed-forward neural network\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),  \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=512\n",
    ")\n",
    "\n",
    "# Predict and evaluate on the validation set\n",
    "y_val_pred_proba = model.predict(X_val)\n",
    "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "\n",
    "accuracy  = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "recall    = recall_score(y_val, y_val_pred, zero_division=0)\n",
    "f1        = f1_score(y_val, y_val_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Report\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f28fc8-bfbf-4cdb-aa53-854e588ab621",
   "metadata": {},
   "source": [
    "A 0.00 recall in class 1 means all actual frauds were missed.\n",
    "\n",
    "Oversampling / Undersampling;\n",
    "Adjust the Threshold;\n",
    "Gather More Fraud Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e077c721-fa07-46b5-91f3-bdf77b7135e2",
   "metadata": {},
   "source": [
    "# simple feed-forward neural network with random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9e33355-1eca-4135-818d-38ca504ebc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define oversampling strategy\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "# fit and apply the transform\n",
    "X_over, y_over = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17751fb8-afb9-46cb-b2fa-b1abff6b5dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pat\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.4994 - loss: 1752860.1250 - val_accuracy: 0.0059 - val_loss: 0.6936\n",
      "Epoch 2/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5001 - loss: 227.9364 - val_accuracy: 0.0059 - val_loss: 0.6933\n",
      "Epoch 3/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5007 - loss: 23.1056 - val_accuracy: 0.9941 - val_loss: 0.6867\n",
      "Epoch 4/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5004 - loss: 6.5733 - val_accuracy: 0.0059 - val_loss: 0.6997\n",
      "Epoch 5/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5002 - loss: 4.8481 - val_accuracy: 0.9941 - val_loss: 0.6901\n",
      "Epoch 6/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4999 - loss: 1.3183 - val_accuracy: 0.0059 - val_loss: 0.6959\n",
      "Epoch 7/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4996 - loss: 2.8443 - val_accuracy: 0.0059 - val_loss: 0.6966\n",
      "Epoch 8/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5006 - loss: 0.6988 - val_accuracy: 0.0059 - val_loss: 0.6936\n",
      "Epoch 9/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 0.6931 - val_accuracy: 0.0059 - val_loss: 0.6945\n",
      "Epoch 10/10\n",
      "\u001b[1m4029/4029\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5000 - loss: 0.6932 - val_accuracy: 0.0059 - val_loss: 0.6937\n",
      "\u001b[1m8105/8105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 866us/step\n",
      "Accuracy:  0.0059\n",
      "Precision: 0.0059\n",
      "Recall:    1.0000\n",
      "F1 Score:  0.0117\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00    257815\n",
      "           1       0.01      1.00      0.01      1520\n",
      "\n",
      "    accuracy                           0.01    259335\n",
      "   macro avg       0.00      0.50      0.01    259335\n",
      "weighted avg       0.00      0.01      0.00    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build a simple feed-forward neural network\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_over.shape[1],)),\n",
    "    Dropout(0.2),  \n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),  \n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_over,\n",
    "    y_over,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=512\n",
    ")\n",
    "\n",
    "# Predict and evaluate on the validation set\n",
    "y_val_pred_proba = model.predict(X_val)\n",
    "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "\n",
    "accuracy  = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "recall    = recall_score(y_val, y_val_pred, zero_division=0)\n",
    "f1        = f1_score(y_val, y_val_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "# Report\n",
    "print(\"\\nDetailed classification report:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce832d9f-6842-4808-8de3-d754d3ddd187",
   "metadata": {},
   "source": [
    "# LSTM with oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "26b4a497-0388-4dbc-9ff6-d2673744eab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pat\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 56ms/step - accuracy: 0.8986 - loss: 0.2369 - val_accuracy: 0.9380 - val_loss: 0.1166\n",
      "Epoch 2/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 56ms/step - accuracy: 0.9608 - loss: 0.0911 - val_accuracy: 0.9242 - val_loss: 0.1386\n",
      "Epoch 3/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 54ms/step - accuracy: 0.9703 - loss: 0.0746 - val_accuracy: 0.9609 - val_loss: 0.0785\n",
      "Epoch 4/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 53ms/step - accuracy: 0.9776 - loss: 0.0609 - val_accuracy: 0.9702 - val_loss: 0.0703\n",
      "Epoch 5/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 53ms/step - accuracy: 0.9830 - loss: 0.0499 - val_accuracy: 0.9779 - val_loss: 0.0556\n",
      "Epoch 6/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m462s\u001b[0m 56ms/step - accuracy: 0.9867 - loss: 0.0425 - val_accuracy: 0.9828 - val_loss: 0.0481\n",
      "Epoch 7/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 56ms/step - accuracy: 0.9895 - loss: 0.0354 - val_accuracy: 0.9851 - val_loss: 0.0453\n",
      "Epoch 8/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m505s\u001b[0m 56ms/step - accuracy: 0.9910 - loss: 0.0316 - val_accuracy: 0.9866 - val_loss: 0.0442\n",
      "Epoch 9/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 57ms/step - accuracy: 0.9924 - loss: 0.0276 - val_accuracy: 0.9863 - val_loss: 0.0463\n",
      "Epoch 10/10\n",
      "\u001b[1m8058/8058\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m511s\u001b[0m 58ms/step - accuracy: 0.9930 - loss: 0.0258 - val_accuracy: 0.9893 - val_loss: 0.0391\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Embedding, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train_lstm = X_over.values.reshape((X_over.shape[0], X_over.shape[1], 1))\n",
    "X_val_lstm = X_val.values.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "# Build LSTM Model\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_over.shape[1], 1)),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitor validation loss\n",
    "    patience=2,          # Stop training after 3 epochs of no improvement\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_lstm, y_over,\n",
    "    validation_data=(X_val_lstm, y_val),\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "800d659a-9166-416e-9432-0c28d9aab9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8105/8105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step\n",
      "ðŸ”¹ LSTM Model Results:\n",
      "Accuracy:  0.9893\n",
      "Precision: 0.3420\n",
      "Recall:    0.8855\n",
      "F1 Score:  0.4934\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    257815\n",
      "           1       0.34      0.89      0.49      1520\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.67      0.94      0.74    259335\n",
      "weighted avg       1.00      0.99      0.99    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict and evaluate on the validation set\n",
    "y_val_pred_proba = model.predict(X_val_lstm)\n",
    "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy  = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred, zero_division=0)\n",
    "recall    = recall_score(y_val, y_val_pred, zero_division=0)\n",
    "f1        = f1_score(y_val, y_val_pred, zero_division=0)\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"ðŸ”¹ LSTM Model Results:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "91b3b8d4-6a09-49dc-b82b-c0aac2900fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"fraud_detection_lstm.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c89e990-72aa-4d8d-b496-da1f472ec4a5",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0014900-6c10-4de5-9e25-a85b46ae59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model in the new Keras format\n",
    "loaded_model = load_model(\"fraud_detection_lstm.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1023c610-de0d-4dd2-9fa8-8b1d1af065a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8105/8105\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    257815\n",
      "           1       0.34      0.89      0.49      1520\n",
      "\n",
      "    accuracy                           0.99    259335\n",
      "   macro avg       0.67      0.94      0.74    259335\n",
      "weighted avg       1.00      0.99      0.99    259335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ensure validation data is reshaped correctly\n",
    "X_val_lstm = X_val.values.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "# Predict fraud probabilities\n",
    "y_val_pred_proba = loaded_model.predict(X_val_lstm)\n",
    "\n",
    "# Convert probabilities to binary predictions (0 or 1)\n",
    "y_val_pred = (y_val_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Evaluate performance\n",
    "print(classification_report(y_val, y_val_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32b7b8ac-c394-44eb-90d5-7c4f8481b204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa028386-5389-44c8-bb1b-e198e3210749",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
